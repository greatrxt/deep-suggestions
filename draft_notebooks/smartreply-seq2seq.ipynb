{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:01.624744Z",
     "iopub.status.busy": "2021-02-20T12:56:01.623734Z",
     "iopub.status.idle": "2021-02-20T12:56:07.543637Z",
     "shell.execute_reply": "2021-02-20T12:56:07.544283Z"
    },
    "papermill": {
     "duration": 5.937688,
     "end_time": "2021-02-20T12:56:07.544673",
     "exception": false,
     "start_time": "2021-02-20T12:56:01.606985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import string, os \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:07.574458Z",
     "iopub.status.busy": "2021-02-20T12:56:07.573763Z",
     "iopub.status.idle": "2021-02-20T12:56:13.098429Z",
     "shell.execute_reply": "2021-02-20T12:56:13.097393Z"
    },
    "papermill": {
     "duration": 5.540955,
     "end_time": "2021-02-20T12:56:13.098586",
     "exception": false,
     "start_time": "2021-02-20T12:56:07.557631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: grpc://10.0.0.2:8470\n",
      "Number of replicas: 8\n",
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:13.131133Z",
     "iopub.status.busy": "2021-02-20T12:56:13.130447Z",
     "iopub.status.idle": "2021-02-20T12:56:13.134230Z",
     "shell.execute_reply": "2021-02-20T12:56:13.133718Z"
    },
    "papermill": {
     "duration": 0.022138,
     "end_time": "2021-02-20T12:56:13.134418",
     "exception": false,
     "start_time": "2021-02-20T12:56:13.112280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 200  # Number of epochs to train for.\n",
    "latent_dim = 512  # Latent dimensionality of the encoding space.\n",
    "num_samples = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:13.167206Z",
     "iopub.status.busy": "2021-02-20T12:56:13.166477Z",
     "iopub.status.idle": "2021-02-20T12:56:13.968719Z",
     "shell.execute_reply": "2021-02-20T12:56:13.968002Z"
    },
    "papermill": {
     "duration": 0.820822,
     "end_time": "2021-02-20T12:56:13.968889",
     "exception": false,
     "start_time": "2021-02-20T12:56:13.148067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you a fan of Google or Microsoft?</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Both are excellent technology they are helpfu...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm not  a huge fan of Google, but I use it a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Google provides online related services and p...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, their services are good. I'm just not a...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id                                            message  \\\n",
       "0                1              Are you a fan of Google or Microsoft?   \n",
       "1                1   Both are excellent technology they are helpfu...   \n",
       "2                1   I'm not  a huge fan of Google, but I use it a...   \n",
       "3                1   Google provides online related services and p...   \n",
       "4                1   Yeah, their services are good. I'm just not a...   \n",
       "\n",
       "                 sentiment  \n",
       "0   Curious to dive deeper  \n",
       "1   Curious to dive deeper  \n",
       "2   Curious to dive deeper  \n",
       "3   Curious to dive deeper  \n",
       "4   Curious to dive deeper  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading dataset\n",
    "df = pd.read_csv('../input/chatbot-dataset-topical-chat/topical_chat.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:14.005289Z",
     "iopub.status.busy": "2021-02-20T12:56:14.004341Z",
     "iopub.status.idle": "2021-02-20T12:56:14.007591Z",
     "shell.execute_reply": "2021-02-20T12:56:14.006963Z"
    },
    "papermill": {
     "duration": 0.024254,
     "end_time": "2021-02-20T12:56:14.007734",
     "exception": false,
     "start_time": "2021-02-20T12:56:13.983480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic preprocessing\n",
    "def process(text):\n",
    "    text = text.lower().replace('\\n', ' ').replace('-', ' ').replace(':', ' ').replace(',', '') \\\n",
    "          .replace('\"', '').replace(\"...\", \".\").replace(\"..\", \".\").replace(\"!\", \".\").replace(\"?\", \" ?\").replace(\";\", \".\").replace(\":\", \" \")\n",
    "\n",
    "    #text = \"\".join(v for v in text if v not in string.punctuation).lower()\n",
    "    #text = text.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "\n",
    "    text = \" \".join(text.split())\n",
    "    #text+=\"<eos>\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:14.042514Z",
     "iopub.status.busy": "2021-02-20T12:56:14.041502Z",
     "iopub.status.idle": "2021-02-20T12:56:14.936033Z",
     "shell.execute_reply": "2021-02-20T12:56:14.935188Z"
    },
    "papermill": {
     "duration": 0.914178,
     "end_time": "2021-02-20T12:56:14.936197",
     "exception": false,
     "start_time": "2021-02-20T12:56:14.022019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.message = df.message.apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:14.977223Z",
     "iopub.status.busy": "2021-02-20T12:56:14.976131Z",
     "iopub.status.idle": "2021-02-20T12:56:14.981791Z",
     "shell.execute_reply": "2021-02-20T12:56:14.981116Z"
    },
    "papermill": {
     "duration": 0.031232,
     "end_time": "2021-02-20T12:56:14.981957",
     "exception": false,
     "start_time": "2021-02-20T12:56:14.950725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>are you a fan of google or microsoft ?</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>both are excellent technology they are helpful...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i'm not a huge fan of google but i use it a lo...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>google provides online related services and pr...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>yeah their services are good. i'm just not a f...</td>\n",
       "      <td>Curious to dive deeper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   conversation_id                                            message  \\\n",
       "0                1             are you a fan of google or microsoft ?   \n",
       "1                1  both are excellent technology they are helpful...   \n",
       "2                1  i'm not a huge fan of google but i use it a lo...   \n",
       "3                1  google provides online related services and pr...   \n",
       "4                1  yeah their services are good. i'm just not a f...   \n",
       "\n",
       "                 sentiment  \n",
       "0   Curious to dive deeper  \n",
       "1   Curious to dive deeper  \n",
       "2   Curious to dive deeper  \n",
       "3   Curious to dive deeper  \n",
       "4   Curious to dive deeper  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:15.038909Z",
     "iopub.status.busy": "2021-02-20T12:56:15.037737Z",
     "iopub.status.idle": "2021-02-20T12:56:15.260512Z",
     "shell.execute_reply": "2021-02-20T12:56:15.259979Z"
    },
    "papermill": {
     "duration": 0.263295,
     "end_time": "2021-02-20T12:56:15.260659",
     "exception": false,
     "start_time": "2021-02-20T12:56:14.997364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2600    18\n",
       "6032    17\n",
       "8490    17\n",
       "3599    17\n",
       "2834    17\n",
       "Name: conversation_id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crudely selecting conversation IDs with ?\n",
    "qa_conversations_mask = df.message.str.contains(\"\\?\")\n",
    "qa_conversations = df.conversation_id[qa_conversations_mask].astype(str).value_counts()\n",
    "qa_conversations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:15.297700Z",
     "iopub.status.busy": "2021-02-20T12:56:15.296665Z",
     "iopub.status.idle": "2021-02-20T12:56:15.316560Z",
     "shell.execute_reply": "2021-02-20T12:56:15.315907Z"
    },
    "papermill": {
     "duration": 0.040587,
     "end_time": "2021-02-20T12:56:15.316725",
     "exception": false,
     "start_time": "2021-02-20T12:56:15.276138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57995"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[qa_conversations_mask].message.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:15.356851Z",
     "iopub.status.busy": "2021-02-20T12:56:15.356044Z",
     "iopub.status.idle": "2021-02-20T12:56:15.360556Z",
     "shell.execute_reply": "2021-02-20T12:56:15.359877Z"
    },
    "papermill": {
     "duration": 0.027935,
     "end_time": "2021-02-20T12:56:15.360757",
     "exception": false,
     "start_time": "2021-02-20T12:56:15.332822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:15.405400Z",
     "iopub.status.busy": "2021-02-20T12:56:15.404647Z",
     "iopub.status.idle": "2021-02-20T12:56:30.393995Z",
     "shell.execute_reply": "2021-02-20T12:56:30.394548Z"
    },
    "papermill": {
     "duration": 15.016215,
     "end_time": "2021-02-20T12:56:30.394752",
     "exception": false,
     "start_time": "2021-02-20T12:56:15.378537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_pairs = list()\n",
    "\n",
    "count = 0\n",
    "\n",
    "for question_index in df[qa_conversations_mask].index:\n",
    "    if count > num_samples:\n",
    "        break\n",
    "    else:\n",
    "        count+=1\n",
    "        \n",
    "    question = df.iloc[question_index].message\n",
    "    \n",
    "    if \".\" in question:\n",
    "        if question.index(\".\") <= len(question):\n",
    "            question = question.split(\".\")[len(question.split(\".\")) - 1].strip()\n",
    "            \n",
    "            \n",
    "    answer = df.iloc[question_index + 1].message\n",
    "    if \".\" in answer:\n",
    "        if answer.index(\".\") <= len(answer):\n",
    "            answer = answer.split('.')[0].strip()\n",
    "    \n",
    "    answer = \"\\t\" + answer + \"\\n\"\n",
    "    \n",
    "    if len(question) < 50 and len(answer) < 50 and question and answer:\n",
    "        input_texts.append(question)\n",
    "        target_texts.append(answer)\n",
    "\n",
    "        for char in question:\n",
    "            if char not in input_characters:\n",
    "                input_characters.add(char)\n",
    "        for char in answer:\n",
    "            if char not in target_characters:\n",
    "                target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:30.445175Z",
     "iopub.status.busy": "2021-02-20T12:56:30.444133Z",
     "iopub.status.idle": "2021-02-20T12:56:31.336763Z",
     "shell.execute_reply": "2021-02-20T12:56:31.336219Z"
    },
    "papermill": {
     "duration": 0.92597,
     "end_time": "2021-02-20T12:56:31.336911",
     "exception": false,
     "start_time": "2021-02-20T12:56:30.410941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 13833\n",
      "Number of unique input tokens: 53\n",
      "Number of unique output tokens: 52\n",
      "Max sequence length for inputs: 49\n",
      "Max sequence length for outputs: 49\n"
     ]
    }
   ],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "#saving\n",
    "with open('input_token_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(input_token_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#saving\n",
    "with open('target_token_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(target_token_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    \n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "        \n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    \n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "            \n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:31.378922Z",
     "iopub.status.busy": "2021-02-20T12:56:31.378091Z",
     "iopub.status.idle": "2021-02-20T12:56:36.354012Z",
     "shell.execute_reply": "2021-02-20T12:56:36.353462Z"
    },
    "papermill": {
     "duration": 5.000635,
     "end_time": "2021-02-20T12:56:36.354167",
     "exception": false,
     "start_time": "2021-02-20T12:56:31.353532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# seq2seq model - https://keras.io/examples/nlp/lstm_seq2seq/\n",
    "with strategy.scope():\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the\n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-20T12:56:36.395829Z",
     "iopub.status.busy": "2021-02-20T12:56:36.395171Z",
     "iopub.status.idle": "2021-02-20T13:12:46.698038Z",
     "shell.execute_reply": "2021-02-20T13:12:46.698587Z"
    },
    "papermill": {
     "duration": 970.326134,
     "end_time": "2021-02-20T13:12:46.698770",
     "exception": false,
     "start_time": "2021-02-20T12:56:36.372636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "195/195 [==============================] - 15s 45ms/step - loss: 1.8140 - accuracy: 0.6054 - val_loss: 1.2009 - val_accuracy: 0.6630\n",
      "Epoch 2/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 1.1220 - accuracy: 0.6804 - val_loss: 0.9522 - val_accuracy: 0.7288\n",
      "Epoch 3/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.9381 - accuracy: 0.7294 - val_loss: 0.8650 - val_accuracy: 0.7495\n",
      "Epoch 4/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 1.0438 - accuracy: 0.7154 - val_loss: 0.8879 - val_accuracy: 0.7472\n",
      "Epoch 5/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.8746 - accuracy: 0.7480 - val_loss: 0.8240 - val_accuracy: 0.7638\n",
      "Epoch 6/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.8226 - accuracy: 0.7617 - val_loss: 0.7887 - val_accuracy: 0.7714\n",
      "Epoch 7/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.7872 - accuracy: 0.7703 - val_loss: 3.0285 - val_accuracy: 0.2389\n",
      "Epoch 8/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.9015 - accuracy: 0.7427 - val_loss: 0.7427 - val_accuracy: 0.7839\n",
      "Epoch 9/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.7495 - accuracy: 0.7839 - val_loss: 0.7155 - val_accuracy: 0.7936\n",
      "Epoch 10/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.7184 - accuracy: 0.7898 - val_loss: 0.6938 - val_accuracy: 0.7985\n",
      "Epoch 11/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.6849 - accuracy: 0.7993 - val_loss: 0.6705 - val_accuracy: 0.8053\n",
      "Epoch 12/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.6625 - accuracy: 0.8057 - val_loss: 0.6510 - val_accuracy: 0.8107\n",
      "Epoch 13/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.6489 - accuracy: 0.8093 - val_loss: 0.6353 - val_accuracy: 0.8157\n",
      "Epoch 14/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.6260 - accuracy: 0.8146 - val_loss: 0.6222 - val_accuracy: 0.8203\n",
      "Epoch 15/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.6082 - accuracy: 0.8205 - val_loss: 0.6080 - val_accuracy: 0.8227\n",
      "Epoch 16/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.6018 - accuracy: 0.8218 - val_loss: 0.5972 - val_accuracy: 0.8248\n",
      "Epoch 17/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.5812 - accuracy: 0.8276 - val_loss: 0.5870 - val_accuracy: 0.8284\n",
      "Epoch 18/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.5601 - accuracy: 0.8332 - val_loss: 0.5773 - val_accuracy: 0.8309\n",
      "Epoch 19/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.5474 - accuracy: 0.8362 - val_loss: 0.5681 - val_accuracy: 0.8329\n",
      "Epoch 20/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.5326 - accuracy: 0.8401 - val_loss: 0.5653 - val_accuracy: 0.8335\n",
      "Epoch 21/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.5214 - accuracy: 0.8429 - val_loss: 0.5568 - val_accuracy: 0.8361\n",
      "Epoch 22/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.5002 - accuracy: 0.8491 - val_loss: 0.5525 - val_accuracy: 0.8372\n",
      "Epoch 23/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.4991 - accuracy: 0.8495 - val_loss: 0.5521 - val_accuracy: 0.8381\n",
      "Epoch 24/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.4815 - accuracy: 0.8549 - val_loss: 0.5474 - val_accuracy: 0.8393\n",
      "Epoch 25/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.4576 - accuracy: 0.8612 - val_loss: 0.5471 - val_accuracy: 0.8408\n",
      "Epoch 26/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.4483 - accuracy: 0.8638 - val_loss: 0.5482 - val_accuracy: 0.8405\n",
      "Epoch 27/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.4342 - accuracy: 0.8683 - val_loss: 0.5504 - val_accuracy: 0.8413\n",
      "Epoch 28/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.4147 - accuracy: 0.8738 - val_loss: 0.5525 - val_accuracy: 0.8410\n",
      "Epoch 29/200\n",
      "195/195 [==============================] - 5s 27ms/step - loss: 0.4013 - accuracy: 0.8778 - val_loss: 0.5554 - val_accuracy: 0.8399\n",
      "Epoch 30/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.3923 - accuracy: 0.8810 - val_loss: 0.5641 - val_accuracy: 0.8398\n",
      "Epoch 31/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.3776 - accuracy: 0.8853 - val_loss: 0.5680 - val_accuracy: 0.8390\n",
      "Epoch 32/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.3606 - accuracy: 0.8909 - val_loss: 0.5737 - val_accuracy: 0.8377\n",
      "Epoch 33/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.3469 - accuracy: 0.8951 - val_loss: 0.5828 - val_accuracy: 0.8379\n",
      "Epoch 34/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.3323 - accuracy: 0.8993 - val_loss: 0.5894 - val_accuracy: 0.8388\n",
      "Epoch 35/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.3210 - accuracy: 0.9025 - val_loss: 0.5999 - val_accuracy: 0.8370\n",
      "Epoch 36/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.3104 - accuracy: 0.9064 - val_loss: 0.6057 - val_accuracy: 0.8368\n",
      "Epoch 37/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2992 - accuracy: 0.9099 - val_loss: 0.6137 - val_accuracy: 0.8363\n",
      "Epoch 38/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2923 - accuracy: 0.9119 - val_loss: 0.6233 - val_accuracy: 0.8364\n",
      "Epoch 39/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2813 - accuracy: 0.9155 - val_loss: 0.6315 - val_accuracy: 0.8359\n",
      "Epoch 40/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2734 - accuracy: 0.9177 - val_loss: 0.6383 - val_accuracy: 0.8358\n",
      "Epoch 41/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2647 - accuracy: 0.9202 - val_loss: 0.6457 - val_accuracy: 0.8344\n",
      "Epoch 42/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2574 - accuracy: 0.9228 - val_loss: 0.6514 - val_accuracy: 0.8343\n",
      "Epoch 43/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2520 - accuracy: 0.9244 - val_loss: 0.6625 - val_accuracy: 0.8338\n",
      "Epoch 44/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2449 - accuracy: 0.9257 - val_loss: 0.6681 - val_accuracy: 0.8346\n",
      "Epoch 45/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2410 - accuracy: 0.9273 - val_loss: 0.6786 - val_accuracy: 0.8328\n",
      "Epoch 46/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2372 - accuracy: 0.9285 - val_loss: 0.6856 - val_accuracy: 0.8337\n",
      "Epoch 47/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2310 - accuracy: 0.9298 - val_loss: 0.6936 - val_accuracy: 0.8320\n",
      "Epoch 48/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2278 - accuracy: 0.9310 - val_loss: 0.6966 - val_accuracy: 0.8327\n",
      "Epoch 49/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2244 - accuracy: 0.9322 - val_loss: 0.7047 - val_accuracy: 0.8322\n",
      "Epoch 50/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2209 - accuracy: 0.9323 - val_loss: 0.7064 - val_accuracy: 0.8338\n",
      "Epoch 51/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2173 - accuracy: 0.9336 - val_loss: 0.7180 - val_accuracy: 0.8334\n",
      "Epoch 52/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2138 - accuracy: 0.9347 - val_loss: 0.7280 - val_accuracy: 0.8337\n",
      "Epoch 53/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2143 - accuracy: 0.9342 - val_loss: 0.7247 - val_accuracy: 0.8330\n",
      "Epoch 54/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2107 - accuracy: 0.9355 - val_loss: 0.7259 - val_accuracy: 0.8340\n",
      "Epoch 55/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2059 - accuracy: 0.9366 - val_loss: 0.7384 - val_accuracy: 0.8330\n",
      "Epoch 56/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2065 - accuracy: 0.9366 - val_loss: 0.7433 - val_accuracy: 0.8330\n",
      "Epoch 57/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2037 - accuracy: 0.9367 - val_loss: 0.7436 - val_accuracy: 0.8335\n",
      "Epoch 58/200\n",
      "195/195 [==============================] - 5s 26ms/step - loss: 0.2024 - accuracy: 0.9375 - val_loss: 0.7513 - val_accuracy: 0.8336\n",
      "Epoch 59/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.2015 - accuracy: 0.9374 - val_loss: 0.7520 - val_accuracy: 0.8330\n",
      "Epoch 60/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1992 - accuracy: 0.9376 - val_loss: 0.7506 - val_accuracy: 0.8342\n",
      "Epoch 61/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1974 - accuracy: 0.9382 - val_loss: 0.7585 - val_accuracy: 0.8335\n",
      "Epoch 62/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1970 - accuracy: 0.9383 - val_loss: 0.7655 - val_accuracy: 0.8335\n",
      "Epoch 63/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1932 - accuracy: 0.9395 - val_loss: 0.7703 - val_accuracy: 0.8336\n",
      "Epoch 64/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1925 - accuracy: 0.9396 - val_loss: 0.7747 - val_accuracy: 0.8334\n",
      "Epoch 65/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1910 - accuracy: 0.9399 - val_loss: 0.7827 - val_accuracy: 0.8335\n",
      "Epoch 66/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1896 - accuracy: 0.9404 - val_loss: 0.7822 - val_accuracy: 0.8324\n",
      "Epoch 67/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1902 - accuracy: 0.9398 - val_loss: 0.7835 - val_accuracy: 0.8324\n",
      "Epoch 68/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1900 - accuracy: 0.9399 - val_loss: 0.7887 - val_accuracy: 0.8327\n",
      "Epoch 69/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1889 - accuracy: 0.9403 - val_loss: 0.7890 - val_accuracy: 0.8329\n",
      "Epoch 70/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1881 - accuracy: 0.9401 - val_loss: 0.7933 - val_accuracy: 0.8332\n",
      "Epoch 71/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1859 - accuracy: 0.9413 - val_loss: 0.7927 - val_accuracy: 0.8338\n",
      "Epoch 72/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1837 - accuracy: 0.9415 - val_loss: 0.7983 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1829 - accuracy: 0.9421 - val_loss: 0.8016 - val_accuracy: 0.8329\n",
      "Epoch 74/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1812 - accuracy: 0.9422 - val_loss: 0.8047 - val_accuracy: 0.8344\n",
      "Epoch 75/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1806 - accuracy: 0.9423 - val_loss: 0.8074 - val_accuracy: 0.8334\n",
      "Epoch 76/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1781 - accuracy: 0.9435 - val_loss: 0.8177 - val_accuracy: 0.8331\n",
      "Epoch 77/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1780 - accuracy: 0.9434 - val_loss: 0.8137 - val_accuracy: 0.8329\n",
      "Epoch 78/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1783 - accuracy: 0.9428 - val_loss: 0.8107 - val_accuracy: 0.8334\n",
      "Epoch 79/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1779 - accuracy: 0.9431 - val_loss: 0.8182 - val_accuracy: 0.8327\n",
      "Epoch 80/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1766 - accuracy: 0.9434 - val_loss: 0.8212 - val_accuracy: 0.8329\n",
      "Epoch 81/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1776 - accuracy: 0.9429 - val_loss: 0.8240 - val_accuracy: 0.8338\n",
      "Epoch 82/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1750 - accuracy: 0.9437 - val_loss: 0.8233 - val_accuracy: 0.8329\n",
      "Epoch 83/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1752 - accuracy: 0.9440 - val_loss: 0.8233 - val_accuracy: 0.8336\n",
      "Epoch 84/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1739 - accuracy: 0.9443 - val_loss: 0.8266 - val_accuracy: 0.8340\n",
      "Epoch 85/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1705 - accuracy: 0.9449 - val_loss: 0.8350 - val_accuracy: 0.8343\n",
      "Epoch 86/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1676 - accuracy: 0.9459 - val_loss: 0.8412 - val_accuracy: 0.8318\n",
      "Epoch 87/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1679 - accuracy: 0.9457 - val_loss: 0.8401 - val_accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1687 - accuracy: 0.9454 - val_loss: 0.8467 - val_accuracy: 0.8337\n",
      "Epoch 89/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1687 - accuracy: 0.9454 - val_loss: 0.8459 - val_accuracy: 0.8330\n",
      "Epoch 90/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1709 - accuracy: 0.9445 - val_loss: 0.8488 - val_accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1739 - accuracy: 0.9433 - val_loss: 0.8474 - val_accuracy: 0.8324\n",
      "Epoch 92/200\n",
      "195/195 [==============================] - 5s 26ms/step - loss: 0.1787 - accuracy: 0.9417 - val_loss: 0.8482 - val_accuracy: 0.8319\n",
      "Epoch 93/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1735 - accuracy: 0.9436 - val_loss: 0.8486 - val_accuracy: 0.8332\n",
      "Epoch 94/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1657 - accuracy: 0.9461 - val_loss: 0.8573 - val_accuracy: 0.8325\n",
      "Epoch 95/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1597 - accuracy: 0.9478 - val_loss: 0.8596 - val_accuracy: 0.8342\n",
      "Epoch 96/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1569 - accuracy: 0.9488 - val_loss: 0.8662 - val_accuracy: 0.8335\n",
      "Epoch 97/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1558 - accuracy: 0.9490 - val_loss: 0.8713 - val_accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1548 - accuracy: 0.9494 - val_loss: 0.8758 - val_accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1539 - accuracy: 0.9502 - val_loss: 0.8741 - val_accuracy: 0.8330\n",
      "Epoch 100/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1556 - accuracy: 0.9491 - val_loss: 0.8802 - val_accuracy: 0.8323\n",
      "Epoch 101/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1598 - accuracy: 0.9483 - val_loss: 0.8755 - val_accuracy: 0.8319\n",
      "Epoch 102/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1817 - accuracy: 0.9405 - val_loss: 0.8640 - val_accuracy: 0.8318\n",
      "Epoch 103/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1917 - accuracy: 0.9364 - val_loss: 0.8558 - val_accuracy: 0.8324\n",
      "Epoch 104/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1738 - accuracy: 0.9430 - val_loss: 0.8557 - val_accuracy: 0.8338\n",
      "Epoch 105/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1581 - accuracy: 0.9484 - val_loss: 0.8677 - val_accuracy: 0.8327\n",
      "Epoch 106/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1512 - accuracy: 0.9509 - val_loss: 0.8752 - val_accuracy: 0.8339\n",
      "Epoch 107/200\n",
      "195/195 [==============================] - 5s 26ms/step - loss: 0.1474 - accuracy: 0.9518 - val_loss: 0.8789 - val_accuracy: 0.8339\n",
      "Epoch 108/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1461 - accuracy: 0.9523 - val_loss: 0.8883 - val_accuracy: 0.8336\n",
      "Epoch 109/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1445 - accuracy: 0.9526 - val_loss: 0.8961 - val_accuracy: 0.8332\n",
      "Epoch 110/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1450 - accuracy: 0.9529 - val_loss: 0.9032 - val_accuracy: 0.8319\n",
      "Epoch 111/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1443 - accuracy: 0.9531 - val_loss: 0.9060 - val_accuracy: 0.8330\n",
      "Epoch 112/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1452 - accuracy: 0.9526 - val_loss: 0.9084 - val_accuracy: 0.8321\n",
      "Epoch 113/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1483 - accuracy: 0.9515 - val_loss: 0.9075 - val_accuracy: 0.8312\n",
      "Epoch 114/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1730 - accuracy: 0.9428 - val_loss: 0.8860 - val_accuracy: 0.8305\n",
      "Epoch 115/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.2106 - accuracy: 0.9289 - val_loss: 0.8673 - val_accuracy: 0.8320\n",
      "Epoch 116/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1713 - accuracy: 0.9431 - val_loss: 0.8740 - val_accuracy: 0.8328\n",
      "Epoch 117/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1510 - accuracy: 0.9510 - val_loss: 0.8781 - val_accuracy: 0.8349\n",
      "Epoch 118/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1419 - accuracy: 0.9540 - val_loss: 0.8925 - val_accuracy: 0.8346\n",
      "Epoch 119/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1383 - accuracy: 0.9545 - val_loss: 0.9026 - val_accuracy: 0.8343\n",
      "Epoch 120/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1365 - accuracy: 0.9551 - val_loss: 0.9098 - val_accuracy: 0.8334\n",
      "Epoch 121/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1355 - accuracy: 0.9551 - val_loss: 0.9178 - val_accuracy: 0.8341\n",
      "Epoch 122/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1352 - accuracy: 0.9551 - val_loss: 0.9271 - val_accuracy: 0.8335\n",
      "Epoch 123/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1357 - accuracy: 0.9554 - val_loss: 0.9304 - val_accuracy: 0.8336\n",
      "Epoch 124/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1346 - accuracy: 0.9557 - val_loss: 0.9344 - val_accuracy: 0.8326\n",
      "Epoch 125/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1364 - accuracy: 0.9554 - val_loss: 0.9359 - val_accuracy: 0.8319\n",
      "Epoch 126/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1493 - accuracy: 0.9510 - val_loss: 0.9263 - val_accuracy: 0.8281\n",
      "Epoch 127/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1982 - accuracy: 0.9335 - val_loss: 0.8967 - val_accuracy: 0.8306\n",
      "Epoch 128/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1759 - accuracy: 0.9410 - val_loss: 0.8953 - val_accuracy: 0.8331\n",
      "Epoch 129/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1500 - accuracy: 0.9507 - val_loss: 0.8981 - val_accuracy: 0.8328\n",
      "Epoch 130/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1387 - accuracy: 0.9548 - val_loss: 0.9073 - val_accuracy: 0.8343\n",
      "Epoch 131/200\n",
      "195/195 [==============================] - 5s 26ms/step - loss: 0.1312 - accuracy: 0.9569 - val_loss: 0.9225 - val_accuracy: 0.8338\n",
      "Epoch 132/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1284 - accuracy: 0.9579 - val_loss: 0.9301 - val_accuracy: 0.8337\n",
      "Epoch 133/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1264 - accuracy: 0.9586 - val_loss: 0.9385 - val_accuracy: 0.8335\n",
      "Epoch 134/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1258 - accuracy: 0.9587 - val_loss: 0.9456 - val_accuracy: 0.8341\n",
      "Epoch 135/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1249 - accuracy: 0.9587 - val_loss: 0.9519 - val_accuracy: 0.8323\n",
      "Epoch 136/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1244 - accuracy: 0.9588 - val_loss: 0.9605 - val_accuracy: 0.8313\n",
      "Epoch 137/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1247 - accuracy: 0.9589 - val_loss: 0.9598 - val_accuracy: 0.8310\n",
      "Epoch 138/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1272 - accuracy: 0.9585 - val_loss: 0.9588 - val_accuracy: 0.8320\n",
      "Epoch 139/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1504 - accuracy: 0.9499 - val_loss: 0.9410 - val_accuracy: 0.8283\n",
      "Epoch 140/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1984 - accuracy: 0.9331 - val_loss: 0.9149 - val_accuracy: 0.8301\n",
      "Epoch 141/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1615 - accuracy: 0.9457 - val_loss: 0.9173 - val_accuracy: 0.8324\n",
      "Epoch 142/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1384 - accuracy: 0.9548 - val_loss: 0.9219 - val_accuracy: 0.8334\n",
      "Epoch 143/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1259 - accuracy: 0.9589 - val_loss: 0.9336 - val_accuracy: 0.8328\n",
      "Epoch 144/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1200 - accuracy: 0.9608 - val_loss: 0.9509 - val_accuracy: 0.8323\n",
      "Epoch 145/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1167 - accuracy: 0.9616 - val_loss: 0.9551 - val_accuracy: 0.8320\n",
      "Epoch 146/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1154 - accuracy: 0.9622 - val_loss: 0.9661 - val_accuracy: 0.8330\n",
      "Epoch 147/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1144 - accuracy: 0.9624 - val_loss: 0.9791 - val_accuracy: 0.8306\n",
      "Epoch 148/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1135 - accuracy: 0.9628 - val_loss: 0.9824 - val_accuracy: 0.8315\n",
      "Epoch 149/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1132 - accuracy: 0.9629 - val_loss: 0.9876 - val_accuracy: 0.8313\n",
      "Epoch 150/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1134 - accuracy: 0.9628 - val_loss: 0.9869 - val_accuracy: 0.8306\n",
      "Epoch 151/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1237 - accuracy: 0.9596 - val_loss: 0.9796 - val_accuracy: 0.8276\n",
      "Epoch 152/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1709 - accuracy: 0.9422 - val_loss: 0.9606 - val_accuracy: 0.8288\n",
      "Epoch 153/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1701 - accuracy: 0.9424 - val_loss: 0.9470 - val_accuracy: 0.8302\n",
      "Epoch 154/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1372 - accuracy: 0.9547 - val_loss: 0.9531 - val_accuracy: 0.8327\n",
      "Epoch 155/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1202 - accuracy: 0.9611 - val_loss: 0.9596 - val_accuracy: 0.8321\n",
      "Epoch 156/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1111 - accuracy: 0.9642 - val_loss: 0.9700 - val_accuracy: 0.8320\n",
      "Epoch 157/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1067 - accuracy: 0.9651 - val_loss: 0.9839 - val_accuracy: 0.8320\n",
      "Epoch 158/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1043 - accuracy: 0.9661 - val_loss: 0.9964 - val_accuracy: 0.8306\n",
      "Epoch 159/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1039 - accuracy: 0.9661 - val_loss: 1.0004 - val_accuracy: 0.8304\n",
      "Epoch 160/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1019 - accuracy: 0.9665 - val_loss: 1.0102 - val_accuracy: 0.8306\n",
      "Epoch 161/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1014 - accuracy: 0.9668 - val_loss: 1.0164 - val_accuracy: 0.8312\n",
      "Epoch 162/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1016 - accuracy: 0.9671 - val_loss: 1.0243 - val_accuracy: 0.8293\n",
      "Epoch 163/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1059 - accuracy: 0.9654 - val_loss: 1.0175 - val_accuracy: 0.8292\n",
      "Epoch 164/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1421 - accuracy: 0.9520 - val_loss: 0.9858 - val_accuracy: 0.8285\n",
      "Epoch 165/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1703 - accuracy: 0.9418 - val_loss: 0.9771 - val_accuracy: 0.8301\n",
      "Epoch 166/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1372 - accuracy: 0.9537 - val_loss: 0.9671 - val_accuracy: 0.8310\n",
      "Epoch 167/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1139 - accuracy: 0.9628 - val_loss: 0.9851 - val_accuracy: 0.8315\n",
      "Epoch 168/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1017 - accuracy: 0.9674 - val_loss: 0.9995 - val_accuracy: 0.8312\n",
      "Epoch 169/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0957 - accuracy: 0.9695 - val_loss: 1.0099 - val_accuracy: 0.8317\n",
      "Epoch 170/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0925 - accuracy: 0.9702 - val_loss: 1.0184 - val_accuracy: 0.8313\n",
      "Epoch 171/200\n",
      "195/195 [==============================] - 5s 26ms/step - loss: 0.0910 - accuracy: 0.9705 - val_loss: 1.0357 - val_accuracy: 0.8305\n",
      "Epoch 172/200\n",
      "195/195 [==============================] - 5s 28ms/step - loss: 0.0890 - accuracy: 0.9712 - val_loss: 1.0395 - val_accuracy: 0.8298\n",
      "Epoch 173/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0891 - accuracy: 0.9710 - val_loss: 1.0477 - val_accuracy: 0.8307\n",
      "Epoch 174/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0880 - accuracy: 0.9716 - val_loss: 1.0566 - val_accuracy: 0.8305\n",
      "Epoch 175/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0891 - accuracy: 0.9710 - val_loss: 1.0577 - val_accuracy: 0.8293\n",
      "Epoch 176/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0959 - accuracy: 0.9689 - val_loss: 1.0590 - val_accuracy: 0.8268\n",
      "Epoch 177/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1495 - accuracy: 0.9491 - val_loss: 1.0088 - val_accuracy: 0.8266\n",
      "Epoch 178/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1516 - accuracy: 0.9484 - val_loss: 1.0071 - val_accuracy: 0.8290\n",
      "Epoch 179/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1192 - accuracy: 0.9604 - val_loss: 1.0046 - val_accuracy: 0.8307\n",
      "Epoch 180/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0976 - accuracy: 0.9685 - val_loss: 1.0224 - val_accuracy: 0.8300\n",
      "Epoch 181/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0863 - accuracy: 0.9727 - val_loss: 1.0365 - val_accuracy: 0.8307\n",
      "Epoch 182/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0815 - accuracy: 0.9742 - val_loss: 1.0535 - val_accuracy: 0.8302\n",
      "Epoch 183/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0786 - accuracy: 0.9750 - val_loss: 1.0645 - val_accuracy: 0.8290\n",
      "Epoch 184/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0762 - accuracy: 0.9754 - val_loss: 1.0729 - val_accuracy: 0.8296\n",
      "Epoch 185/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0760 - accuracy: 0.9755 - val_loss: 1.0876 - val_accuracy: 0.8282\n",
      "Epoch 186/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0749 - accuracy: 0.9759 - val_loss: 1.0932 - val_accuracy: 0.8289\n",
      "Epoch 187/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0750 - accuracy: 0.9758 - val_loss: 1.0971 - val_accuracy: 0.8279\n",
      "Epoch 188/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.0746 - accuracy: 0.9760 - val_loss: 1.1093 - val_accuracy: 0.8267\n",
      "Epoch 189/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0794 - accuracy: 0.9747 - val_loss: 1.0967 - val_accuracy: 0.8264\n",
      "Epoch 190/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1389 - accuracy: 0.9527 - val_loss: 1.0490 - val_accuracy: 0.8259\n",
      "Epoch 191/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.1548 - accuracy: 0.9472 - val_loss: 1.0321 - val_accuracy: 0.8292\n",
      "Epoch 192/200\n",
      "195/195 [==============================] - 5s 25ms/step - loss: 0.1099 - accuracy: 0.9632 - val_loss: 1.0388 - val_accuracy: 0.8292\n",
      "Epoch 193/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0879 - accuracy: 0.9717 - val_loss: 1.0452 - val_accuracy: 0.8309\n",
      "Epoch 194/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0764 - accuracy: 0.9760 - val_loss: 1.0640 - val_accuracy: 0.8303\n",
      "Epoch 195/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0704 - accuracy: 0.9781 - val_loss: 1.0759 - val_accuracy: 0.8295\n",
      "Epoch 196/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0673 - accuracy: 0.9788 - val_loss: 1.0877 - val_accuracy: 0.8281\n",
      "Epoch 197/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0657 - accuracy: 0.9790 - val_loss: 1.0999 - val_accuracy: 0.8293\n",
      "Epoch 198/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0635 - accuracy: 0.9796 - val_loss: 1.1099 - val_accuracy: 0.8283\n",
      "Epoch 199/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0637 - accuracy: 0.9796 - val_loss: 1.1182 - val_accuracy: 0.8286\n",
      "Epoch 200/200\n",
      "195/195 [==============================] - 5s 24ms/step - loss: 0.0629 - accuracy: 0.9798 - val_loss: 1.1296 - val_accuracy: 0.8271\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T13:12:54.841359Z",
     "iopub.status.busy": "2021-02-20T13:12:54.840702Z",
     "iopub.status.idle": "2021-02-20T13:12:55.069354Z",
     "shell.execute_reply": "2021-02-20T13:12:55.068844Z"
    },
    "papermill": {
     "duration": 4.356793,
     "end_time": "2021-02-20T13:12:55.069495",
     "exception": false,
     "start_time": "2021-02-20T13:12:50.712702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T13:13:03.229480Z",
     "iopub.status.busy": "2021-02-20T13:13:03.218793Z",
     "iopub.status.idle": "2021-02-20T13:13:03.412992Z",
     "shell.execute_reply": "2021-02-20T13:13:03.412395Z"
    },
    "papermill": {
     "duration": 4.26571,
     "end_time": "2021-02-20T13:13:03.413134",
     "exception": false,
     "start_time": "2021-02-20T13:12:59.147424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save(\"s2s.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T13:13:11.583294Z",
     "iopub.status.busy": "2021-02-20T13:13:11.577743Z",
     "iopub.status.idle": "2021-02-20T13:13:12.668219Z",
     "shell.execute_reply": "2021-02-20T13:13:12.668726Z"
    },
    "papermill": {
     "duration": 5.231899,
     "end_time": "2021-02-20T13:13:12.668916",
     "exception": false,
     "start_time": "2021-02-20T13:13:07.437017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Restore the model and construct the encoder and decoder.\n",
    "model = keras.models.load_model(\"./s2s.hdf5\")\n",
    "\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_3\")\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_4\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T13:13:20.817094Z",
     "iopub.status.busy": "2021-02-20T13:13:20.816054Z",
     "iopub.status.idle": "2021-02-20T13:13:43.856491Z",
     "shell.execute_reply": "2021-02-20T13:13:43.856989Z"
    },
    "papermill": {
     "duration": 27.106512,
     "end_time": "2021-02-20T13:13:43.857188",
     "exception": false,
     "start_time": "2021-02-20T13:13:16.750676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: do you use it as well for your browser ?\n",
      "Decoded sentence: i love basketball\n",
      "\n",
      "-\n",
      "Input sentence: by the way do you like fish ?\n",
      "Decoded sentence: yes i do\n",
      "\n",
      "-\n",
      "Input sentence: did you know that jellyfish are immortal ?\n",
      "Decoded sentence: yes\n",
      "\n",
      "-\n",
      "Input sentence: do you like dance ?\n",
      "Decoded sentence: i love it\n",
      "\n",
      "-\n",
      "Input sentence: did you know babies are really good at dancing ?\n",
      "Decoded sentence: yes and they smile more when they hit the beat\n",
      "\n",
      "-\n",
      "Input sentence: do you like shakespeare ?\n",
      "Decoded sentence: i love his work\n",
      "\n",
      "-\n",
      "Input sentence: say what now ? ? they have that ? ?\n",
      "Decoded sentence: yeah apparently lol\n",
      "\n",
      "-\n",
      "Input sentence: do you like to dance ?\n",
      "Decoded sentence: i do not\n",
      "\n",
      "-\n",
      "Input sentence: how about you ?\n",
      "Decoded sentence: i agree\n",
      "\n",
      "-\n",
      "Input sentence: do you like dance ?\n",
      "Decoded sentence: i love it\n",
      "\n",
      "-\n",
      "Input sentence: did you know bruce lee was a dancer ?\n",
      "Decoded sentence: yes he even won a cha cha championship in 1958\n",
      "\n",
      "-\n",
      "Input sentence: did you know ballet dancers use a lot of shoes ?\n",
      "Decoded sentence: yes they go through 4 pairs in a single week\n",
      "\n",
      "-\n",
      "Input sentence: did you know tupac was a ballet dancer ?\n",
      "Decoded sentence: i didn't know that\n",
      "\n",
      "-\n",
      "Input sentence: do you like shakespeare ?\n",
      "Decoded sentence: i love his work\n",
      "\n",
      "-\n",
      "Input sentence: how about you ? do you use gmail ?\n",
      "Decoded sentence: i do like albums\n",
      "\n",
      "-\n",
      "Input sentence: do you know how google maps calculates traffic ?\n",
      "Decoded sentence: i am not sure how do they do this ?\n",
      "\n",
      "-\n",
      "Input sentence: i am not sure how do they do this ?\n",
      "Decoded sentence: they track how fast android devices are moving\n",
      "\n",
      "-\n",
      "Input sentence: have you ever typed askew into google ?\n",
      "Decoded sentence: no i have\n",
      "\n",
      "-\n",
      "Input sentence: what does the results turn ?\n",
      "Decoded sentence: i have no idea it doesn't explain much\n",
      "\n",
      "-\n",
      "Input sentence: or is this mean ?\n",
      "Decoded sentence: oh not sure about that really\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(20):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T13:13:51.982228Z",
     "iopub.status.busy": "2021-02-20T13:13:51.981580Z",
     "iopub.status.idle": "2021-02-20T13:13:53.182375Z",
     "shell.execute_reply": "2021-02-20T13:13:53.182931Z"
    },
    "papermill": {
     "duration": 5.266092,
     "end_time": "2021-02-20T13:13:53.183103",
     "exception": false,
     "start_time": "2021-02-20T13:13:47.917011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: good morning\n",
      "Decoded sentence: i was when i was younger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"good morning\"\n",
    "encoded_text = np.zeros(\n",
    "    (1, max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "for t, char in enumerate(text):\n",
    "    encoded_text[0, t, input_token_index[char]] = 1.0\n",
    "    \n",
    "decoded_sentence = decode_sequence(encoded_text)\n",
    "print(\"-\")\n",
    "print(\"Input sentence:\", text)\n",
    "print(\"Decoded sentence:\", decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1082.923894,
   "end_time": "2021-02-20T13:13:58.840125",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-20T12:55:55.916231",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
